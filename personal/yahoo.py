# âœ… ì „ì²´ í†µí•© ì½”ë“œ: GA ìµœì í™” í¬í•¨ ì£¼ê°€ ì˜ˆì¸¡ + RSI/MACD ì‹œê°í™” í¬í•¨
from curl_cffi import requests
import yfinance as yf
import pandas as pd
import numpy as np
import random
import datetime
import matplotlib.pyplot as plt
import tensorflow as tf
import os
import json
from pyESN import ESN
from tensorflow.keras.layers import LSTM
from sklearn.metrics import mean_squared_error

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.linear_model import LinearRegression
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

from scipy import stats
import numpy as np

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ë‚ ì§œ ì„¤ì •
end_date = datetime.datetime.today()
start_date = end_date - datetime.timedelta(weeks=600)

# âœ… yfinance 429 ìš°íšŒ ì„¸ì…˜ ì ìš© - curl_cffi ê¸°ë°˜ Chrome user-agent ì„¸ì…˜ì„ í™œìš©í•˜ì—¬ ìš°íšŒ ë‹¤ìš´ë¡œë“œ
session = requests.Session(impersonate="chrome")

# ë°±ì—… ê²½ë¡œ
raw_data_path = "aapl_raw_backup.csv"

# ë°±ì—…ì´ ìˆê³ , í˜•ì‹ì´ ì˜¬ë°”ë¥¸ ê²½ìš° ë¡œë“œ
use_backup = False
if os.path.exists(raw_data_path):
    try:
        df_test = pd.read_csv(raw_data_path, index_col=0, parse_dates=True)
        if pd.to_numeric(df_test['Close'], errors='coerce').notnull().all():
            data = df_test
            use_backup = True
            print("âœ… ë°±ì—…ëœ ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
    except Exception as e:
        print("âŒ ë°±ì—… íŒŒì¼ ì˜¤ë¥˜, ì¬ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤:", e)

if not use_backup:
    ticker = yf.Ticker("AAPL", session=session)
    data = ticker.history(period="600wk")
    if not data.empty:
        data.to_csv(raw_data_path)
        print("ğŸ“¦ ì›ë³¸ ë°ì´í„° ë°±ì—… ì €ì¥ ì™„ë£Œ.")
    else:
        raise RuntimeError("âŒ yfinanceì—ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

close_prices = data[['Close']].copy()

# âœ… ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ (RSI, MACD)
def compute_RSI(series, period=14):
    delta = series.diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    rs = avg_gain / avg_loss
    return 100 - (100 / (1 + rs))

def compute_MACD(series):
    ema12 = series.ewm(span=12, adjust=False).mean()
    ema26 = series.ewm(span=26, adjust=False).mean()
    macd = ema12 - ema26
    signal = macd.ewm(span=9, adjust=False).mean()
    return macd, signal

def plot_gru_vs_esn(real_val_close, pred_val_gru, pred_val_esn):
    plt.figure(figsize=(12, 6))
    plt.plot(real_val_close[-50:], label='ğŸ“ˆ ì‹¤ì œ ì¢…ê°€', color='black', marker='o', linewidth=2)
    plt.plot(pred_val_gru[-50:], label='ğŸ§  GRU ì˜ˆì¸¡', linestyle='--', color='orange', marker='x', linewidth=2)
    plt.plot(pred_val_esn[-50:], label='ğŸ” ESN ì˜ˆì¸¡', linestyle=':', color='blue', marker='s', linewidth=2)

    plt.title("ìµœê·¼ 10ì£¼ ì˜ˆì¸¡ ë¹„êµ: GRU vs ESN (RSI+MACD)", fontsize=14)
    plt.xlabel("ìµœê·¼ ë‚ ì§œ ìˆœì„œ", fontsize=12)
    plt.ylabel("ê°€ê²© (USD)", fontsize=12)
    plt.legend(fontsize=10)
    plt.grid(True)
    plt.tight_layout()
    plt.figtext(
        0.5, -0.02,
        f"GRU MSE={mean_squared_error(real_val_close[-50:], pred_val_gru[-50:]):.4f} | "
        f"ESN MSE={mean_squared_error(real_val_close[-50:], pred_val_esn[-50:]):.4f}",
        ha="center", fontsize=10
    )
    plt.show()

def run_esn_and_plot(scaled_data, seq_len, split, scaler_close, real_val_close, pred_val_close):
    # ì‹œê³„ì—´ ìƒ˜í”Œ ìƒì„± í•¨ìˆ˜ ì¤‘ë³µ ì •ì˜
    def create_sequences(data, seq_length):
        x, y = [], []
        for i in range(len(data) - seq_length):
            x.append(data[i:i + seq_length])
            y.append(data[i + seq_length])
        return np.array(x), np.array(y)

    # ë°ì´í„° ìƒì„±
    X_esn, _ = create_sequences(scaled_data, seq_len)
    _, y_esn = create_sequences(scaled_close, seq_len)

    # reshape for ESN
    X_esn = X_esn.reshape(X_esn.shape[0], seq_len * scaled_data.shape[1])
    X_esn_train, X_esn_val = X_esn[:split], X_esn[split:]
    y_esn_train, y_esn_val = y_esn[:split], y_esn[split:]

    esn = ESN(
        n_inputs=seq_len * scaled_data.shape[1],
        n_outputs=1,
        n_reservoir=500,
        spectral_radius=0.95,
        sparsity=0.1,
        noise=0.0001,
        random_state=42
    )
    esn.fit(X_esn_train, y_esn_train)
    pred_val_esn = esn.predict(X_esn_val)
    pred_val_esn = np.clip(pred_val_esn, 0, 0.9)  # â†’ ìµœëŒ€ê°’ì´ ì™„ì „íˆ 1ì— ìˆ˜ë ´í•˜ëŠ” ê±¸ ë°©ì§€
    pred_val_esn_close = scaler_close.inverse_transform(pred_val_esn.reshape(-1, 1))

    plot_gru_vs_esn(real_val_close, pred_val_close, pred_val_esn_close)
    return pred_val_esn_close

close_prices['RSI'] = compute_RSI(close_prices['Close'])
close_prices['MACD'], close_prices['MACD_signal'] = compute_MACD(close_prices['Close'])

# ì´ìƒì¹˜ í´ë¦¬í•‘ í•¨ìˆ˜ ì •ì˜ (1% ì´í•˜, 99% ì´ìƒ ê°’ì„ ì ˆë‹¨í•˜ì—¬ ì™œê³¡ ë°©ì§€)
def clip_outliers(series, lower_quantile=0.01, upper_quantile=0.99):
    q_low = series.quantile(lower_quantile)
    q_high = series.quantile(upper_quantile)
    return series.clip(lower=q_low, upper=q_high)

# RSI, MACD, Signalì— í´ë¦¬í•‘ ì ìš©
close_prices['RSI'] = clip_outliers(close_prices['RSI'])
close_prices['MACD'] = clip_outliers(close_prices['MACD'])
close_prices['MACD_signal'] = clip_outliers(close_prices['MACD_signal'])

# 1. ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ” êµ¬ê°„ë§Œ ì„ íƒ (RSI, MACD, Signal ëª¨ë‘ í¬í•¨)
valid_df = close_prices.dropna(subset=['RSI', 'MACD', 'MACD_signal']).copy()

# 2. ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”
scaler_close = MinMaxScaler()
scaler_rsi = MinMaxScaler()
scaler_macd = MinMaxScaler()
scaler_signal = MinMaxScaler()

# 3. ì •ê·œí™” (ì •ìƒ êµ¬ê°„ë§Œ)
scaled_close = scaler_close.fit_transform(valid_df[['Close']])
scaled_rsi = scaler_rsi.fit_transform(valid_df[['RSI']])
scaled_macd = scaler_macd.fit_transform(valid_df[['MACD']])
scaled_signal = scaler_signal.fit_transform(valid_df[['MACD_signal']])

# 4. ìµœì¢… í†µí•©ëœ ì…ë ¥ ë°ì´í„° êµ¬ì„±
scaled_data = np.hstack([scaled_close, scaled_rsi, scaled_macd, scaled_signal])

# ì‹œê³„ì—´ ìƒ˜í”Œ ìƒì„± í•¨ìˆ˜
def create_sequences(data, seq_length):
    x, y = [], []
    for i in range(len(data) - seq_length):
        x.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(x), np.array(y)

# âœ… GA ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¶ˆëŸ¬ì˜¤ê¸°
ga_param_path = "best_hyperparams_final_aapl.json"
if not os.path.exists(ga_param_path):
    raise FileNotFoundError("GA ìµœì í™” íŒŒë¼ë¯¸í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

with open(ga_param_path, 'r') as f:
    best_params = json.load(f)

seq_len = best_params['seq_len']
gru_units_1 = best_params['gru_units_1']
gru_units_2 = best_params['gru_units_2']
dropout = best_params['dropout']
batch_size = best_params['batch_size']
learning_rate = best_params['learning_rate']

X, _ = create_sequences(scaled_data, seq_len)
_, y = create_sequences(scaled_close, seq_len)
# GRU ì…ë ¥ì„ ìœ„í•œ ë‹¤ì°¨ì› êµ¬ì¡°ë¡œ ë³€ê²½
X = X.reshape((X.shape[0], X.shape[1], scaled_data.shape[1]))

split = int(len(X) * 0.8)
X_train, X_val = X[:split], X[split:]
y_train, y_val = y[:split], y[split:]

# ëª¨ë¸ êµ¬ì„± ë° í•™ìŠµ
early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)
model = Sequential([
    GRU(gru_units_1, return_sequences=True, input_shape=(seq_len, X.shape[2])),
    Dropout(dropout),
    GRU(gru_units_2),
    Dropout(dropout),
    Dense(1)
])
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')
history = model.fit(X_train, y_train, epochs=100, batch_size=batch_size,
                    validation_data=(X_val, y_val), callbacks=[early_stop], verbose=1)

# ì˜ˆì¸¡ ë° ì—­ì •ê·œí™”
pred_train = model.predict(X_train)
pred_val = model.predict(X_val)

# ì˜ˆì¸¡ê°’ì€ ì¢…ê°€(Close)ë§Œ ì—­ì •ê·œí™”
pred_train_close = scaler_close.inverse_transform(pred_train)
pred_val_close = scaler_close.inverse_transform(pred_val)
real_train_close = scaler_close.inverse_transform(y_train[:pred_train.shape[0]].reshape(-1, 1))
real_val_close = valid_df['Close'].values.reshape(-1, 1)[-len(pred_val):]
pred_val = scaler_close.inverse_transform(pred_val)

# ê¸°ì¡´ ì˜ˆì¸¡ ì‹œê°í™”
window = 20
if len(pred_val) >= window:
    x_range = np.arange(window).reshape(-1, 1)
    y_range = pred_val[-window:]
    reg = LinearRegression()
    reg.fit(x_range, y_range)
    slope = reg.coef_[0][0]
    if slope > 0.5:
        trend = "ê°•í•œ ìƒìŠ¹ ğŸ“ˆ"
    elif slope > 0.1:
        trend = "ì™„ë§Œí•œ ìƒìŠ¹ â¬†ï¸"
    elif slope < -0.5:
        trend = "ê°•í•œ í•˜ê°• ğŸ“‰"
    elif slope < -0.1:
        trend = "ì™„ë§Œí•œ í•˜ê°• â¬‡ï¸"
    else:
        trend = "íš¡ë³´ â–"
else:
    slope = 0
    trend = "ë°ì´í„° ë¶€ì¡±"

fig, axs = plt.subplots(1, 2, figsize=(16, 6))
axs[0].plot(np.concatenate([real_train_close, real_val_close]), label='ì‹¤ì œ ì¢…ê°€', linewidth=2, color='black')
axs[0].plot(np.concatenate([pred_train_close, pred_val_close]), label='ì˜ˆì¸¡ ì¢…ê°€', linewidth=2, linestyle='--', color='orange')
if len(pred_val) >= window:
    trend_line = reg.predict(x_range)
    axs[0].plot(
        np.arange(len(real_train_close) + len(real_val_close) - window, len(real_train_close) + len(real_val_close)),
        trend_line, label='ì˜ˆì¸¡ ì¶”ì„¸ì„ ', linestyle=':', color='red')
axs[0].set_title(f"ì „ì²´ ì˜ˆì¸¡ (600ì£¼) - RSI + MACD í¬í•¨ | ì˜ˆì¸¡ ê¸°ë°˜ ì¶”ì„¸: {trend} (ê¸°ìš¸ê¸°={slope:.4f})", fontsize=13)
axs[0].set_xlabel('ì‹œê°„ ìˆœì„œ', fontsize=12)
axs[0].set_ylabel('ê°€ê²© (USD)', fontsize=12)
axs[0].legend()
axs[0].grid(True)

axs[1].plot(real_val_close[-50:], label='ì‹¤ì œ ì¢…ê°€', marker='o', linewidth=2)
axs[1].plot(pred_val_close[-50:], label='ì˜ˆì¸¡ ì¢…ê°€', marker='o', linewidth=2, linestyle='--')
axs[1].set_title("ìµœê·¼ 10ì£¼ ì˜ˆì¸¡", fontsize=13)
axs[1].set_xlabel("ìµœê·¼ ë‚ ì§œ ìˆœì„œ", fontsize=12)
axs[1].set_ylabel("ê°€ê²© (USD)", fontsize=12)
axs[1].legend()
axs[1].grid(True)

plt.tight_layout()
plt.figtext(0.5, -0.05, "âœ… ì…ë ¥ features: [Close, RSI, MACD, MACD Signal]", ha="center", fontsize=10)
plt.show()

# âœ… ë¹„êµ ì‹¤í—˜: Close-only ì…ë ¥ ë²„ì „ìœ¼ë¡œ í•™ìŠµ ë° ì‹œê°í™”
X_base, _ = create_sequences(scaled_close, seq_len)
_, y_base = create_sequences(scaled_close, seq_len)
X_base = X_base.reshape((X_base.shape[0], X_base.shape[1], 1))
X_base_train, X_base_val = X_base[:split], X_base[split:]
y_base_train, y_base_val = y_base[:split], y_base[split:]

model_base = Sequential([
    GRU(gru_units_1, return_sequences=True, input_shape=(seq_len, 1)),
    Dropout(dropout),
    GRU(gru_units_2),
    Dropout(dropout),
    Dense(1)
])
model_base.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')
model_base.fit(X_base_train, y_base_train, epochs=100, batch_size=batch_size,
               validation_data=(X_base_val, y_base_val), callbacks=[early_stop], verbose=0)

pred_val_base = model_base.predict(X_base_val)
pred_val_base_close = scaler_close.inverse_transform(pred_val_base)

model_lstm = Sequential([
    LSTM(gru_units_1, return_sequences=True, input_shape=(seq_len, X.shape[2])),
    Dropout(dropout),
    LSTM(gru_units_2),
    Dropout(dropout),
    Dense(1)
])
model_lstm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')
history_lstm = model_lstm.fit(
    X_train, y_train,
    epochs=100,
    batch_size=batch_size,
    validation_data=(X_val, y_val),
    callbacks=[early_stop],
    verbose=1
)

# âœ… LSTM ì˜ˆì¸¡ ê²°ê³¼
pred_val_lstm = model_lstm.predict(X_val)
pred_val_lstm_close = scaler_close.inverse_transform(pred_val_lstm)

# âœ… ESN ì˜ˆì¸¡ë„ ì—¬ê¸°ì„œ ë°›ì•„ì˜´ (í•¨ìˆ˜ ì‹¤í–‰)
pred_val_esn_close = run_esn_and_plot(scaled_data, seq_len, split, scaler_close, real_val_close, pred_val_close)

# âœ… ìµœì¢… ë¹„êµ ì‹œê°í™” (ìµœê·¼ 10ì£¼)
plt.figure(figsize=(12, 6))
plt.plot(real_val_close[-50:], label='ğŸ“ˆ ì‹¤ì œ ì¢…ê°€', marker='o', linewidth=2)
plt.plot(pred_val_close[-50:], label='ğŸ§  GRU ì˜ˆì¸¡', linestyle='--', marker='x', linewidth=2)
plt.plot(pred_val_lstm_close[-50:], label='ğŸ”® LSTM ì˜ˆì¸¡', linestyle='-.', marker='^', linewidth=2)
plt.plot(pred_val_esn_close[-50:], label='ğŸ” ESN ì˜ˆì¸¡', linestyle=':', marker='s', linewidth=2)
plt.title("ìµœê·¼ 10ì£¼ ì˜ˆì¸¡ ë¹„êµ: GRU vs LSTM vs ESN", fontsize=14)
plt.xlabel("ìµœê·¼ ë‚ ì§œ ìˆœì„œ", fontsize=12)
plt.ylabel("ê°€ê²© (USD)", fontsize=12)
plt.legend(fontsize=10)
plt.grid(True)
plt.tight_layout()
plt.show()

# ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
pred_all = model.predict(X)
pred_all_close = scaler_close.inverse_transform(pred_all)
real_all = scaler_close.inverse_transform(y.reshape(-1, 1))

result_df = close_prices.copy().reset_index()
result_df.columns = ['date', 'real_price', 'RSI', 'MACD', 'MACD_signal']
result_df['predicted_price'] = np.nan
n_pred = pred_all_close.flatten().shape[0]
result_df.loc[seq_len:seq_len + n_pred - 1, 'predicted_price'] = pred_all_close.flatten()
result_df['trend'] = trend
result_df['slope'] = round(float(slope), 4)

# ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì—¬ëŸ¬ ê°œì˜ MSE ê³„ì‚°
def sliding_mse(real, pred, window=10, step=10):
    mse_list = []
    for i in range(0, len(real) - window + 1, step):
        mse = mean_squared_error(real[i:i+window], pred[i:i+window])
        mse_list.append(mse)
    return np.array(mse_list)

gru_mse = sliding_mse(real_val_close, pred_val_close, window=10, step=10)
lstm_mse = sliding_mse(real_val_close, pred_val_lstm_close, window=10, step=10)

# 1. ë‘ ìƒ˜í”Œì˜ t-ê²€ì • (ë‘ í‘œë³¸ í‰ê·  ì°¨ì´ì— ëŒ€í•œ ê²€ì •)
t_stat, p_value = stats.ttest_ind(gru_mse, lstm_mse)

# 2. p-value ì¶œë ¥
print(f"t-ê²€ì • í†µê³„ëŸ‰ (t-statistic): {t_stat}")
print(f"p-value: {p_value}")

# 3. p-value ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ í•´ì„
alpha = 0.05  # ìœ ì˜ìˆ˜ì¤€ (5%)
if p_value < alpha:
    print("ëŒ€ë¦½ê°€ì„¤ì„ ì±„íƒí•©ë‹ˆë‹¤: ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.")
else:
    print("ê·€ë¬´ê°€ì„¤ì„ ì±„íƒí•©ë‹ˆë‹¤: ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤.")

result_df.to_csv("aapl_lstm_enhanced_with_plot.csv", index=False, encoding='utf-8-sig')
print("âœ… ì „ì²´ ì˜ˆì¸¡ í¬í•¨ CSV ì €ì¥ ì™„ë£Œ: 'aapl_lstm_enhanced_with_plot.csv'")
print(f"ğŸ“ˆ ì˜ˆì¸¡ ê¸°ë°˜ ì¶”ì„¸: {trend} (ê¸°ìš¸ê¸°={slope:.4f})")
# í•™ìŠµ ë° ê²€ì¦ ì˜ˆì¸¡ ê²°ê³¼ê°€ ê°ê° pred_train, pred_valì— ì €ì¥ëœ ìƒíƒœ
mse_train, rmse_train, mae_train = mean_squared_error(real_train_close, pred_train_close), np.sqrt(mean_squared_error(real_train_close, pred_train_close)), mean_absolute_error(real_train_close, pred_train_close)
mse_val, rmse_val, mae_val = mean_squared_error(real_val_close, pred_val_close), np.sqrt(mean_squared_error(real_val_close, pred_val_close)), mean_absolute_error(real_val_close, pred_val_close)
print(f"ğŸ“Š í•™ìŠµ MSE: {mse_train:.4f}, ê²€ì¦ MSE: {mse_val:.4f}")

